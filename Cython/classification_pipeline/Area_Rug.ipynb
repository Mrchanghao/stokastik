{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import CustomClassifier\n",
    "reload(CustomClassifier)\n",
    "import CustomFeatureTransformer\n",
    "reload(CustomFeatureTransformer)\n",
    "import random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from CustomFeatureTransformer import AreaRugTransformer\n",
    "from CustomClassifier import AreaRugClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import re, time\n",
    "from scipy.sparse import hstack\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\"/Users/a0m02fp/area_rug_tagged_data.csv\")\n",
    "\n",
    "df[u'product_name'].apply(str)\n",
    "df[u'product_short_description'].apply(str)\n",
    "df[u'product_long_description'].apply(str)\n",
    "df[u'Manual curation'].apply(str)\n",
    "\n",
    "# df = df.loc[df[u'Manual curation'] != 'None']\n",
    "\n",
    "df_title_data = lambda dataF: list(dataF[u'product_name'])\n",
    "df_desc_data = lambda dataF: list(dataF[u'product_short_description'] + \" \" + dataF[u'product_long_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "train_df, test_df = df[msk], df[~msk]\n",
    "\n",
    "train_sents_title, test_sents_title = map(lambda x:str(x), df_title_data(train_df)), map(lambda x:str(x), df_title_data(test_df))\n",
    "train_sents_desc, test_sents_desc = map(lambda x:str(x), df_desc_data(train_df)), map(lambda x:str(x), df_desc_data(test_df))\n",
    "\n",
    "train_labels, test_labels = list(train_df[u'Manual curation']), list(test_df[u'Manual curation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0485470295\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "transformer_title, transformer_desc = AreaRugTransformer(num_features=30, max_ngram=2), AreaRugTransformer(num_features=30, max_ngram=2)\n",
    "\n",
    "transformer_title.fit(train_sents_title, train_labels)\n",
    "transformer_desc.fit(train_sents_desc, train_labels)\n",
    "\n",
    "train_title_data, train_desc_data = transformer_title.transform(train_sents_title), transformer_desc.transform(train_sents_desc)\n",
    "\n",
    "train_data = hstack((train_title_data, train_desc_data))\n",
    "print time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "Hand-Knotted Rugs       0.99      0.88      0.93       182\n",
      "Hand-Tufted Rugs       0.97      0.83      0.89       299\n",
      "       None       0.95      0.99      0.97      1494\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1975\n",
      "\n",
      "1.40019798279\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "base_estimator = LogisticRegression(penalty='l1')\n",
    "\n",
    "model = AreaRugClassifier(base_estimator, train_title_data.shape[1], predict_threshold=0.5)\n",
    "model.fit(train_data, train_labels)\n",
    "\n",
    "test_title_data, test_desc_data = transformer_title.transform(test_sents_title), transformer_desc.transform(test_sents_desc)\n",
    "\n",
    "test_data = hstack((test_title_data, test_desc_data))\n",
    "\n",
    "print model.score(test_data, test_labels)\n",
    "print time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.33 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test_title_data, test_desc_data = transformer_title.transform(test_sents_title[0:1]), transformer_desc.transform(test_sents_desc[0:1])\n",
    "test_data = hstack((test_title_data, test_desc_data))\n",
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"10x12 Mashad Persian Area Rug This rug comes with free shipping and free 30 days return for full refund with no question asked. At Rugsource we offer 100% Satisfaction guaranteed at the wholesale price so everyone can have a beautiful rug in their house to bring warmth and joy by adding a handmade rug.<br><ul><li>Rug Age : 40-50 Years Old</li><li>Condition : Very Good ( Low Pile )</li><li>Rug Style : Mashad</li><li>Primary Color : Red &amp; Burgundies</li><li>Weave Type : Hand Knotted</li><li>Rug Size : 12' 2'' X 9' 9''</li><li>Rug Shape : Rectangle</li></ul>\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sents_desc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/log/models/color_category/description_transform.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_folder = '/log/models/color_category'\n",
    "\n",
    "class_names_file = os.path.join(model_folder, 'class_names.pkl')\n",
    "title_transform_file = os.path.join(model_folder, 'titles_transform.pkl')\n",
    "description_transform_file = os.path.join(model_folder, 'description_transform.pkl')\n",
    "model_file = os.path.join(model_folder, 'model.pkl')\n",
    "\n",
    "joblib.dump(model.class_labels, class_names_file)\n",
    "joblib.dump(model, model_file)\n",
    "joblib.dump(transformer_title, title_transform_file)\n",
    "joblib.dump(transformer_desc, description_transform_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.mlb.inverse_transform(model.predict(test_data))\n",
    "pred_labels = map(lambda x:'__'.join(x), pred_labels)\n",
    "\n",
    "test_df['Predicted Label'] = pred_labels\n",
    "\n",
    "test_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.predict(test_data)\n",
    "test_df['Inhouse_Model_Predicted'] = pred_labels\n",
    "test_df.to_csv(\"/Users/a0m02fp/Predictions_Area_Rug.csv\", encoding='utf-8', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named model_selection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-f882e8be6f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named model_selection"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in kf.split(df):\n",
    "    train_df, test_df = df.iloc[train_index], df.iloc[test_index]\n",
    "    \n",
    "    train_sents_title, test_sents_title = map(lambda x:str(x), df_title_data(train_df)), map(lambda x:str(x), df_title_data(test_df))\n",
    "    train_sents_desc, test_sents_desc = map(lambda x:str(x), df_desc_data(train_df)), map(lambda x:str(x), df_desc_data(test_df))\n",
    "\n",
    "    train_labels, test_labels = list(train_df[u'Manual curation']), list(test_df[u'Manual curation'])\n",
    "\n",
    "    transformer_title, transformer_desc = AreaRugTransformer(), AreaRugTransformer()\n",
    "\n",
    "    transformer_title.fit(train_sents_title, train_labels, num_features=20)\n",
    "    transformer_desc.fit(train_sents_desc, train_labels, num_features=50)\n",
    "\n",
    "    train_title_data, train_desc_data = transformer_title.transform(train_sents_title), transformer_desc.transform(train_sents_desc)\n",
    "\n",
    "    train_data = hstack((train_title_data, train_desc_data))\n",
    "\n",
    "    base_estimator = LogisticRegression(penalty='l1')\n",
    "\n",
    "    model = AreaRugClassifier(base_estimator, train_title_data.shape[1])\n",
    "    model.fit(train_data, train_labels)\n",
    "\n",
    "    test_title_data, test_desc_data = transformer_title.transform(test_sents_title), transformer_desc.transform(test_sents_desc)\n",
    "\n",
    "    test_data = hstack((test_title_data, test_desc_data))\n",
    "\n",
    "    print model.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 5]\n",
      " [5 1 9]\n",
      " [7 8 0]]\n",
      "[[6 9 1]\n",
      " [3 2 5]\n",
      " [1 6 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6, 9, 5],\n",
       "       [5, 2, 9],\n",
       "       [7, 8, 3]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[2,3,5],[5,1,9],[7,8,0]])\n",
    "b = np.array([[6,9,1],[3,2,5],[1,6,3]])\n",
    "print a\n",
    "print b\n",
    "np.maximum.reduce([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i',\n",
       " u'me',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'we',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'you',\n",
       " u\"you're\",\n",
       " u\"you've\",\n",
       " u\"you'll\",\n",
       " u\"you'd\",\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves',\n",
       " u'he',\n",
       " u'him',\n",
       " u'his',\n",
       " u'himself',\n",
       " u'she',\n",
       " u\"she's\",\n",
       " u'her',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'it',\n",
       " u\"it's\",\n",
       " u'its',\n",
       " u'itself',\n",
       " u'they',\n",
       " u'them',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'themselves',\n",
       " u'what',\n",
       " u'which',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'this',\n",
       " u'that',\n",
       " u\"that'll\",\n",
       " u'these',\n",
       " u'those',\n",
       " u'am',\n",
       " u'is',\n",
       " u'are',\n",
       " u'was',\n",
       " u'were',\n",
       " u'be',\n",
       " u'been',\n",
       " u'being',\n",
       " u'have',\n",
       " u'has',\n",
       " u'had',\n",
       " u'having',\n",
       " u'do',\n",
       " u'does',\n",
       " u'did',\n",
       " u'doing',\n",
       " u'a',\n",
       " u'an',\n",
       " u'the',\n",
       " u'and',\n",
       " u'but',\n",
       " u'if',\n",
       " u'or',\n",
       " u'because',\n",
       " u'as',\n",
       " u'until',\n",
       " u'while',\n",
       " u'of',\n",
       " u'at',\n",
       " u'by',\n",
       " u'for',\n",
       " u'with',\n",
       " u'about',\n",
       " u'against',\n",
       " u'between',\n",
       " u'into',\n",
       " u'through',\n",
       " u'during',\n",
       " u'before',\n",
       " u'after',\n",
       " u'above',\n",
       " u'below',\n",
       " u'to',\n",
       " u'from',\n",
       " u'up',\n",
       " u'down',\n",
       " u'in',\n",
       " u'out',\n",
       " u'on',\n",
       " u'off',\n",
       " u'over',\n",
       " u'under',\n",
       " u'again',\n",
       " u'further',\n",
       " u'then',\n",
       " u'once',\n",
       " u'here',\n",
       " u'there',\n",
       " u'when',\n",
       " u'where',\n",
       " u'why',\n",
       " u'how',\n",
       " u'all',\n",
       " u'any',\n",
       " u'both',\n",
       " u'each',\n",
       " u'few',\n",
       " u'more',\n",
       " u'most',\n",
       " u'other',\n",
       " u'some',\n",
       " u'such',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'only',\n",
       " u'own',\n",
       " u'same',\n",
       " u'so',\n",
       " u'than',\n",
       " u'too',\n",
       " u'very',\n",
       " u's',\n",
       " u't',\n",
       " u'can',\n",
       " u'will',\n",
       " u'just',\n",
       " u'don',\n",
       " u\"don't\",\n",
       " u'should',\n",
       " u\"should've\",\n",
       " u'now',\n",
       " u'd',\n",
       " u'll',\n",
       " u'm',\n",
       " u'o',\n",
       " u're',\n",
       " u've',\n",
       " u'y',\n",
       " u'ain',\n",
       " u'aren',\n",
       " u\"aren't\",\n",
       " u'couldn',\n",
       " u\"couldn't\",\n",
       " u'didn',\n",
       " u\"didn't\",\n",
       " u'doesn',\n",
       " u\"doesn't\",\n",
       " u'hadn',\n",
       " u\"hadn't\",\n",
       " u'hasn',\n",
       " u\"hasn't\",\n",
       " u'haven',\n",
       " u\"haven't\",\n",
       " u'isn',\n",
       " u\"isn't\",\n",
       " u'ma',\n",
       " u'mightn',\n",
       " u\"mightn't\",\n",
       " u'mustn',\n",
       " u\"mustn't\",\n",
       " u'needn',\n",
       " u\"needn't\",\n",
       " u'shan',\n",
       " u\"shan't\",\n",
       " u'shouldn',\n",
       " u\"shouldn't\",\n",
       " u'wasn',\n",
       " u\"wasn't\",\n",
       " u'weren',\n",
       " u\"weren't\",\n",
       " u'won',\n",
       " u\"won't\",\n",
       " u'wouldn',\n",
       " u\"wouldn't\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
