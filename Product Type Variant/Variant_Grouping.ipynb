{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/libs/base/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import siamese_network\n",
    "importlib.reload(siamese_network)\n",
    "from siamese_network import SiameseNet\n",
    "\n",
    "import siamese_api\n",
    "importlib.reload(siamese_api)\n",
    "from siamese_api import SiameseAPI\n",
    "\n",
    "import data_generator as dg\n",
    "importlib.reload(dg)\n",
    "\n",
    "import grouping\n",
    "importlib.reload(grouping)\n",
    "from grouping import Grouping\n",
    "\n",
    "import pandas as pd, random, pickle, numpy as np, tables, sys, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sapi = SiameseAPI(model_file_path='data/siamese_model_new.h5', max_words=50, embedding_size=64, batch_size=32)\n",
    "sapi.get_model()\n",
    "sapi.model.init_model()\n",
    "sapi.model.load()\n",
    "sapi.kdtree = dg.load_data_pkl('kdtree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Women Casual V-Neck Short Sleeve Solid Elastic Pullover T-Shirt Top ECBY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41991591453552246\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "ind = sapi.get_nearest_neighbors(sentence)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3964170196056366, 0.39590346813201904, 0.9287691116333008)\n"
     ]
    }
   ],
   "source": [
    "print(sapi.benchmark_kdtree(num_samples=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for i in random.sample(range(len(items)), 1000):\n",
    "    start = time.time()\n",
    "    ind = tree.query_radius([embeddings[i]], r=0.693)\n",
    "    times.append(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.428667068481445"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Women Casual V-Neck Short Sleeve Solid Elastic Pullover T-Shirt Top ECBY'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Mens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n",
      "Hamilton Ohio T-Shirt Home of Ohio State University and OSU Buckeyes Bearcats  Artix Womens Shirts\n"
     ]
    }
   ],
   "source": [
    "for x in ind[0]:\n",
    "    print(items[x][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = pd.read_csv(\"grouping_validation_set.csv\")\n",
    "gs_items = pd.read_csv(\"items_gs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'item_id', 'title'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_items.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "base_item_ids = list(validation_set['Item Id'])\n",
    "grouped_item_ids = list(validation_set['Items to be grouped'])\n",
    "\n",
    "gs_mapping = collections.defaultdict(list)\n",
    "for i in range(len(base_item_ids)):\n",
    "    gs_mapping[base_item_ids[i]].append(grouped_item_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_item_title_map = dict()\n",
    "gs_item_titles = list(gs_items['title'])\n",
    "gs_item_ids = list(gs_items['item_id'])\n",
    "\n",
    "for i in range(len(gs_item_ids)):\n",
    "    gs_item_title_map[gs_item_ids[i]] = gs_item_titles[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sapi = SiameseAPI(model_file_path='data/siamese_model_new.h5', max_words=50, embedding_size=64, batch_size=32)\n",
    "sapi.get_model()\n",
    "sapi.model.init_model()\n",
    "sapi.model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_embeddings = sapi.model.get_embeddings(gs_item_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.save_data_pkl(gs_embeddings, 'gs_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_item_embed_map = dict()\n",
    "\n",
    "for i in range(len(gs_item_ids)):\n",
    "    gs_item_embed_map[gs_item_ids[i]] = gs_embeddings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "sapi.kdtree = KDTree(gs_embeddings, leaf_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9724247646824871\n",
      "0.3891040263116015\n"
     ]
    }
   ],
   "source": [
    "num_predicted, num_actual, num_correct = 0, 0, 0\n",
    "\n",
    "for base_item_id, grouped_item_ids in gs_mapping.items():\n",
    "    if base_item_id in gs_item_embed_map:\n",
    "        nearest = sapi.kdtree.query_radius([gs_item_embed_map[base_item_id]], r=0.693)[0]\n",
    "        predicted_item_ids = [gs_item_ids[x] for x in nearest]\n",
    "        num_correct += len(set(grouped_item_ids).intersection(set(predicted_item_ids)))\n",
    "        num_predicted += len(predicted_item_ids)\n",
    "        num_actual += len(grouped_item_ids)\n",
    "\n",
    "precision = float(num_correct)/num_predicted\n",
    "recall = float(num_correct)/num_actual\n",
    "\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = dg.load_data_pkl('items.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_instance = Grouping(items)\n",
    "groups = grp_instance.true_grouping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Fetching important attributes...\"\n",
    "var_instance1 = Variant(groups1, items, max_attrs_per_var=1, max_variants=10, excluded_attrs=excluded_attrs)\n",
    "valid_attrs = set([attr[0] for attr, score in var_instance1.get_variant_scores()])\n",
    "    \n",
    "print \"Fetching variant criteria...\"\n",
    "var_instance = Variant(groups1, items, max_attrs_per_var=2, max_variants=1, excluded_attrs=excluded_attrs, valid_attrs=valid_attrs)\n",
    "variant_scores = var_instance.get_variant_scores()\n",
    "\n",
    "print \"Predominant Variant Criteria : \", variant_scores[0]\n",
    "\n",
    "print \"Fetching variant criteria per group...\"\n",
    "pred_grp_variants = var_instance.get_predicted_variants()\n",
    "\n",
    "print \"Results\"\n",
    "var_instance.results(pred_grp_variants, variant_scores[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2vec_api import Word2VecAPI\n",
    "wapi = Word2VecAPI(items)\n",
    "wapi.train_model()\n",
    "wapi.insert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random\n",
    "times = []\n",
    "for i in random.sample(range(len(items)), 1000):\n",
    "    start = time.time()\n",
    "    d = wapi.get_nearest_neighbors_mongo(items[i][2], groups, head_thres=0.5, ind_thres=0.999)\n",
    "    times.append(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in d:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_embeds = wapi.get_representations([str(x[2]) for x in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_instance2 = Grouping(items, representations=w_embeds, similarity_threshold=0.1)\n",
    "grp_instance2.init_groups()\n",
    "groups2 = grp_instance2.auto_groups\n",
    "print grp_instance2.get_clustering_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(groups2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Fetching important attributes...\"\n",
    "var_instance1 = Variant(groups2, items, max_attrs_per_var=1, max_variants=10, excluded_attrs=excluded_attrs)\n",
    "valid_attrs = set([attr[0] for attr, score in var_instance1.get_variant_scores()])\n",
    "    \n",
    "print \"Fetching variant criteria...\"\n",
    "var_instance = Variant(groups2, items, max_attrs_per_var=2, max_variants=1, excluded_attrs=excluded_attrs, valid_attrs=valid_attrs)\n",
    "variant_scores = var_instance.get_variant_scores()\n",
    "\n",
    "print \"Predominant Variant Criteria : \", variant_scores[0]\n",
    "\n",
    "print \"Fetching variant criteria per group...\"\n",
    "pred_grp_variants = var_instance.get_predicted_variants()\n",
    "\n",
    "print \"Results\"\n",
    "var_instance.results(pred_grp_variants, variant_scores[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "tree1 = KDTree(s_embeds, leaf_size=50)\n",
    "tree2 = KDTree(w_embeds, leaf_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = tree1.query_radius(s_embeds[2], r=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = tree2.query_radius(w_embeds[2], r=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ind[0]:\n",
    "    print items[x][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "tree = KDTree(np.tile(embeds.T, 50).T, leaf_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tree.pkl', 'wb') as f:\n",
    "    pickle.dump(tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random\n",
    "\n",
    "out = []\n",
    "for j in range(5, 50, 5):\n",
    "    tree = KDTree(np.tile(embeds.T, j).T, leaf_size=50)\n",
    "    w = random.sample(range(len(items)), 1000)\n",
    "    times = []\n",
    "    for i in w:\n",
    "        start = time.time()\n",
    "        ind = tree.query_radius(embeds[i], r=0.02)\n",
    "        duration = time.time()-start\n",
    "        times.append(duration)\n",
    "    out.append((j, np.max(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out + [(50, 0.028570890426635742)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "w = random.sample(range(len(items)), 1000)\n",
    "times = []\n",
    "for i in w:\n",
    "    start = time.time()\n",
    "    ind = tree.query_radius(embeds[i], r=0.02)\n",
    "    duration = time.time()-start\n",
    "    times.append(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "175*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import plot\n",
    "\n",
    "x, y = zip(*out)\n",
    "plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75863792747259"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22280.845237731934/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables\n",
    "sents_arr_file = tables.open_file('data/sent_arrays.h5', mode='r')\n",
    "sents_arr = sents_arr_file.root.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([169372, 403212, 485034, 320809, 248157, 402627,  42651, 457089,\n",
       "       287069, 314260, 402629, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922, 112922, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922, 112922, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922, 112922, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922, 112922, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_map = dg.load_data_pkl('word2idx_map.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[169372,\n",
       " 403212,\n",
       " 485034,\n",
       " 320809,\n",
       " 248157,\n",
       " 402627,\n",
       " 42651,\n",
       " 457089,\n",
       " 287069,\n",
       " 314260,\n",
       " 402629,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922,\n",
       " 112922]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dg.word_to_idx(w.decode('utf-8'), word2idx_map) for w in sent_tokens[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2idx_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6dfa686824ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mML_USER_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"homeoffice\\\\a0m02fp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msent_arr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msent_arr_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-6dfa686824ff>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mML_USER_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"homeoffice\\\\a0m02fp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msent_arr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msent_arr_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word2idx_map' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sent_arr_1 = [np.asarray([dg.word_to_idx(w, word2idx_map) for w in sent_tokens[0]])]\n",
    "sent_arr_2 = [np.asarray([dg.word_to_idx(w, word2idx_map) for w in sent_tokens[1]])]\n",
    "\n",
    "pred = siamese_net.predict([sent_arr_1, sent_arr_2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maui Hawaii Boy Youth Shirts T-Shirt Tee'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[500][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables\n",
    "\n",
    "def get_items_sampled(items, num_groups=10000):\n",
    "    try:\n",
    "        tokens_file = tables.open_file('data/sent_tokens.h5', mode='r')\n",
    "        sent_tokens = tokens_file.root.data\n",
    "\n",
    "        grp_instance = Grouping(items)\n",
    "        groups = grp_instance.true_grouping()\n",
    "\n",
    "        group_ids = [key for key, vals in groups.items() if len(vals) >= 5]\n",
    "\n",
    "        random.seed(42)\n",
    "        random_group_ids = random.sample(group_ids, num_groups)\n",
    "\n",
    "        selected_items_indices = []\n",
    "        for gid in random_group_ids:\n",
    "            selected_items_indices += groups[gid]\n",
    "\n",
    "        selected_items_indices = sorted(selected_items_indices)\n",
    "        print(len(selected_items_indices))\n",
    "\n",
    "        items = [items[i] for i in selected_items_indices]\n",
    "        sent_tokens_out = sent_tokens[selected_items_indices,:]\n",
    "        \n",
    "        tokens_file.close()\n",
    "\n",
    "        return items, sent_tokens_out\n",
    "    \n",
    "    finally:\n",
    "        tokens_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17469\n"
     ]
    }
   ],
   "source": [
    "items, sent_tokens = get_items_sampled(items, num_groups=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cancer Awareness T-Shirt Kiss Breast Cancer GoodBye Cancer Cancer Awareness Ribbon Cancer Support Gifts Artix Women's Slouchy T-Shirt Clothes\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[500][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'b\"cancer', b'awareness', b't-shirt', b'kiss', b'breast',\n",
       "       b'cancer', b'goodbye', b'cancer', b'cancer', b'awareness',\n",
       "       b'ribbon', b'cancer', b'support', b'gift', b'artix', b\"women's\",\n",
       "       b'slouchy', b't-shirt', b'clothes\"', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT',\n",
       "       b'PAD_TXT', b'PAD_TXT', b'PAD_TXT', b'PAD_TXT'], dtype='|S16')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_generator as dg\n",
    "data_pairs = dg.load_data_pkl(\"train_data_pairs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "items1, items2, labels = zip(*data_pairs)\n",
    "items1, items2, labels = np.array(items1), np.array(items2), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3834845, 355485, 10761044, 816603, 12018381, 7067327, 6523749, 4716772, 3814661, 145964]\n"
     ]
    }
   ],
   "source": [
    "print(items1[0:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Selection lists cannot have repeated values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/base_env/py3-anaconda-base/lib/python3.6/site-packages/tables/array.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# First, try with a regular selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/base_env/py3-anaconda-base/lib/python3.6/site-packages/tables/array.py\u001b[0m in \u001b[0;36m_interpret_indexing\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Non-valid index or slice: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mellipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Non-valid index or slice: [1, 1]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/base_env/py3-anaconda-base/lib/python3.6/site-packages/tables/array.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                 \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_point_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/base_env/py3-anaconda-base/lib/python3.6/site-packages/tables/leaf.py\u001b[0m in \u001b[0;36m_point_selection\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only integer coordinates allowed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0;31m# We absolutely need a contiguous array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integer coordinates allowed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-eac544680b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mML_USER_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"homeoffice\\\\a0m02fp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msents_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/base_env/py3-anaconda-base/lib/python3.6/site-packages/tables/array.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0;31m# Finally, try with a fancy selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fancy_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/base_env/py3-anaconda-base/lib/python3.6/site-packages/tables/array.py\u001b[0m in \u001b[0;36m_fancy_selection\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnexp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                     raise IndexError(\n\u001b[0;32m--> 584\u001b[0;31m                         \"Selection lists cannot have repeated values\")\n\u001b[0m\u001b[1;32m    585\u001b[0m                 \u001b[0mneworder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 if (neworder.shape != (len(exp),) or\n",
      "\u001b[0;31mIndexError\u001b[0m: Selection lists cannot have repeated values"
     ]
    }
   ],
   "source": [
    "sents_arr[[1,1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([224237, 257937, 503506, 458512, 462271, 465599, 296584, 430360,\n",
       "       477761, 488932, 294699, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922, 112922, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922, 112922, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922, 112922, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922, 112922, 112922, 112922, 112922, 112922, 112922,\n",
       "       112922, 112922], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187307530779818"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "g = lambda x: math.exp(-x)\n",
    "g(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4965853037914095"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
