{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('/Users/a0m02fp/pt_list_dump_image_urls.tsv', sep='\\\\t', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, min(len(obj.index), 8000), False),:]\n",
    "df_sample = df.groupby('product_type', as_index=False).apply(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(\"non_placeholder_image_urls.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "prod_urls = []\n",
    "for url in urls:\n",
    "    if isinstance(url, basestring):\n",
    "        x = json.loads(url)\n",
    "        if len(x) > 1:\n",
    "            prod_urls.append(x[1])\n",
    "        else:\n",
    "            prod_urls.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"non_placeholder_image_urls.txt\", 'w') as f:\n",
    "    for url in prod_urls:\n",
    "        f.write(url + os.linesep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class Image_Array_Generator(Sequence):\n",
    "    def __init__(self, data_pairs, batch_size):\n",
    "        self.data_pairs = data_pairs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.data_pairs) / float(self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_data_pairs = self.data_pairs[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        urls1, urls2, labels = zip(*batch_data_pairs)\n",
    "        \n",
    "        image_data1 = np.array([img_to_array(load_img(url).resize((128, 128))) for url in urls1])/255.0\n",
    "        image_data2 = np.array([img_to_array(load_img(url).resize((128, 128))) for url in urls2])/255.0\n",
    "\n",
    "        return [image_data1, image_data2], np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_generator = Image_Array_Generator(train_data_pairs, 256)\n",
    "testing_batch_generator = Image_Array_Generator(test_data_pairs, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6512 samples, validate on 724 samples\n",
      "Epoch 1/5\n",
      "6512/6512 [==============================] - 89s 14ms/step - loss: 1.5266 - acc: 0.7299 - val_loss: 1.3599 - val_acc: 0.7942\n",
      "Epoch 2/5\n",
      "6512/6512 [==============================] - 86s 13ms/step - loss: 1.2675 - acc: 0.8394 - val_loss: 1.1520 - val_acc: 0.8412\n",
      "Epoch 3/5\n",
      "6512/6512 [==============================] - 87s 13ms/step - loss: 1.1078 - acc: 0.8713 - val_loss: 1.0922 - val_acc: 0.8384\n",
      "Epoch 4/5\n",
      "6512/6512 [==============================] - 88s 14ms/step - loss: 0.9870 - acc: 0.8934 - val_loss: 0.9231 - val_acc: 0.9006\n",
      "Epoch 5/5\n",
      "6512/6512 [==============================] - 87s 13ms/step - loss: 0.8950 - acc: 0.9049 - val_loss: 0.9004 - val_acc: 0.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c2bda10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, concatenate, Lambda, merge\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input1, input2 = Input(shape=(64,64,3)), Input(shape=(64,64,3))\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=(11, 11), padding='same', activation='relu', kernel_regularizer=l2(2e-4))\n",
    "conv_a, conv_b = conv(input1), conv(input2)\n",
    "\n",
    "max_pool = MaxPooling2D(pool_size=(2, 2))\n",
    "max_pool_a, max_pool_b = max_pool(conv_a), max_pool(conv_b)\n",
    "\n",
    "conv = Conv2D(filters=64, kernel_size=(7, 7), padding='same', activation='relu', kernel_regularizer=l2(2e-4))\n",
    "conv_a, conv_b = conv(max_pool_a), conv(max_pool_b)\n",
    "\n",
    "max_pool = MaxPooling2D(pool_size=(2, 2))\n",
    "max_pool_a, max_pool_b = max_pool(conv_a), max_pool(conv_b)\n",
    "\n",
    "\n",
    "flatten = Flatten()\n",
    "flatten_a, flatten_b = flatten(max_pool_a), flatten(max_pool_b)\n",
    "\n",
    "dense = Dense(512, activation=\"sigmoid\", kernel_regularizer=l2(1e-3))\n",
    "dense_a, dense_b = dense(flatten_a), dense(flatten_b)\n",
    "\n",
    "merged = Lambda(lambda x: K.abs(x[0]-x[1]))([dense_a, dense_b])\n",
    "\n",
    "out = Dense(1, activation=\"sigmoid\")(merged)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=out)\n",
    "\n",
    "optimizer = Adam(lr=0.00005, clipnorm=5.)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit([image_data1, image_data2], labels, batch_size=256, epochs=5, validation_split=0.1, verbose=1)\n",
    "\n",
    "model.fit_generator(generator=training_batch_generator,\n",
    "                  steps_per_epoch=(len(train_data_pairs) // 256),\n",
    "                  epochs=5,\n",
    "                  verbose=1,\n",
    "                  validation_data=testing_batch_generator,\n",
    "                  validation_steps=(len(test_data_pairs) // 256),\n",
    "                  use_multiprocessing=True,\n",
    "                  workers=5,\n",
    "                  max_queue_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob, hashlib, os\n",
    "\n",
    "d_placeholder_images = glob.glob(\"downloaded_placeholder_images/*.*\")\n",
    "\n",
    "for img_path in d_placeholder_images:\n",
    "    im = Image.open(img_path)\n",
    "    rgb_im = im.convert('RGB')\n",
    "    md5_hash = hashlib.md5(img_path.encode('utf-8')).hexdigest()\n",
    "    rgb_im.save(os.path.join(\"downloaded_placeholder_images\" , md5_hash + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/libs/base/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import unimodel_classifier\n",
    "importlib.reload(unimodel_classifier)\n",
    "\n",
    "from unimodel_classifier import UniModel\n",
    "import data_generator as dg\n",
    "importlib.reload(dg)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "image_data, labels = dg.get_image_data_unimodel('test')\n",
    "\n",
    "image_shape = (image_data.shape[1], image_data.shape[2], image_data.shape[3])\n",
    "\n",
    "unimodel = UniModel(\"data/unimodel.h5\")\n",
    "unimodel.init_model(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense_2/bias/Assign (defined at /home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:402)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_2/bias, dense_2/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense_2/bias/Assign', defined at:\n  File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib64/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/lib64/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/usr/lib64/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-2c084dde7640>\", line 17, in <module>\n    unimodel.init_model(image_shape)\n  File \"/home/jupyter/stormbreaker/placeholder_detection/unimodel_classifier.py\", line 43, in init_model\n    out = Dense(1, activation=\"sigmoid\")(dropout)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/layers/core.py\", line 872, in build\n    constraint=self.bias_constraint)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/engine/base_layer.py\", line 252, in add_weight\n    constraint=constraint)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1481, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense_2/bias/Assign (defined at /home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:402)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_2/bias, dense_2/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node dense_2/bias/Assign}} = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_2/bias, dense_2/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-94dcc338a0b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mML_USER_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"homeoffice\\\\a0m02fp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munimodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0munimodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stormbreaker/placeholder_detection/unimodel_classifier.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1166\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                              ' elements.')\n\u001b[1;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense_2/bias/Assign (defined at /home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:402)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_2/bias, dense_2/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense_2/bias/Assign', defined at:\n  File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib64/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/lib64/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/usr/lib64/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-2c084dde7640>\", line 17, in <module>\n    unimodel.init_model(image_shape)\n  File \"/home/jupyter/stormbreaker/placeholder_detection/unimodel_classifier.py\", line 43, in init_model\n    out = Dense(1, activation=\"sigmoid\")(dropout)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/layers/core.py\", line 872, in build\n    constraint=self.bias_constraint)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/engine/base_layer.py\", line 252, in add_weight\n    constraint=constraint)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1481, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense_2/bias/Assign (defined at /home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:402)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_2/bias, dense_2/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "unimodel.load()\n",
    "unimodel.score(image_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import siamese_predictor\n",
    "reload(siamese_predictor)\n",
    "\n",
    "from siamese_predictor import SiameseModel\n",
    "import data_generator as dg\n",
    "reload(dg)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "image_data, labels = dg.get_image_data_siamese('test')\n",
    "\n",
    "image_shape = (image_data[0].shape[1], image_data[0].shape[2], image_data[0].shape[3])\n",
    "\n",
    "siamese_model = SiameseModel(\"data/siamese_model.h5\")\n",
    "siamese_model.init_model(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.79      0.87      4576\n",
      "          1       0.82      0.98      0.89      4576\n",
      "\n",
      "avg / total       0.89      0.88      0.88      9152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "siamese_model.load()\n",
    "siamese_model.score(image_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashing_predictor as hp\n",
    "reload(hp)\n",
    "from hashing_predictor import Hashing\n",
    "import glob, os\n",
    "\n",
    "hashing = Hashing(threshold=15)\n",
    "train_image_files = glob.glob(os.path.join(\"tagged_placeholder_images\", \"*.*\"))\n",
    "hashing.fit(train_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97      3863\n",
      "          1       0.97      0.96      0.96      3263\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7126\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "hashing.threshold = 15\n",
    "pos_image_files = glob.glob(os.path.join(\"similar_placeholder_images\", \"*.*\"))\n",
    "neg_image_files = glob.glob(os.path.join(\"product_images\", \"*.*\"))\n",
    "\n",
    "print hashing.score(pos_image_files, neg_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [1, 2, 3, 4],\n",
       "       [1, 2, 3, 4],\n",
       "       [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.repeat([[1,2,3,4]], 4, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100000/256.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "int(math.ceil(float(100000)/256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
